START : 2024-05-29 14:39:29

General parameters for data and model
- seed = 1005 (default = 1005)
- arch = resnet18
- batch_size = 64 (default = 64)
- workers = 8 (default = 4)
- data_path = data/ImageNet

Quantization parameters
- n_bits_w = 4 (default = 4)
- channel_wise = True (default = True)
- n_bits_a = 4 (default = 4)
- disable_8bit_head_stem = not use (action = 'store_true')

Weight calibration parameters
- num_samples = 1024 (default = 1024)
- iters_w = 20000 (default = 20000)
- weight = 0.01 (default = 0.01)
- keep_cpu = not use (action = 'store_true')
- b_start = 20 (default = 20)
- b_end = 2 (default = 2)
- warmup = 0.2 (default = 0.2)

Activation calibration parameters
- lr = 4e-5 (default = 4e-5)
- init_wmode = mse (default = 'mse', choices = ['minmax', 'mse', 'minmax_scale'])
- init_amode = mse (default = 'mse', choices = ['minmax', 'mse', 'minmax_scale'])
- prob = 0.5 (default = 0.5)
- input_prob = 0.5 (default = 0.5)
- lamb_r = 0.1 (default = 0.1)
- T = 20 (default = 4.0)
- bn_lr = 1e-3 (default = 1e-3)
- lamb_c = 0.02 (default = 0.02)

-------------------------------------------------------------------------------------------

==> Using Pytorch Dataset
the quantized model is below!
QuantModel(
  (model): ResNet(
    (conv1): QuantModule(
      wbit=4, abit=4, disable_act_quant=False
      (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
      (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
      (norm_function): StraightThrough()
      (activation_function): ReLU(inplace=True)
    )
    (bn1): StraightThrough()
    (relu): StraightThrough()
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): QuantBasicBlock(
        (conv1): QuantModule(
          wbit=4, abit=4, disable_act_quant=False
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): ReLU(inplace=True)
        )
        (conv2): QuantModule(
          wbit=4, abit=4, disable_act_quant=True
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): StraightThrough()
        )
        (activation_function): ReLU(inplace=True)
        (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
      )
      (1): QuantBasicBlock(
        (conv1): QuantModule(
          wbit=4, abit=4, disable_act_quant=False
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): ReLU(inplace=True)
        )
        (conv2): QuantModule(
          wbit=4, abit=4, disable_act_quant=True
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): StraightThrough()
        )
        (activation_function): ReLU(inplace=True)
        (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
      )
    )
    (layer2): Sequential(
      (0): QuantBasicBlock(
        (conv1): QuantModule(
          wbit=4, abit=4, disable_act_quant=False
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): ReLU(inplace=True)
        )
        (conv2): QuantModule(
          wbit=4, abit=4, disable_act_quant=True
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): StraightThrough()
        )
        (downsample): QuantModule(
          wbit=4, abit=4, disable_act_quant=True
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): StraightThrough()
        )
        (activation_function): ReLU(inplace=True)
        (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
      )
      (1): QuantBasicBlock(
        (conv1): QuantModule(
          wbit=4, abit=4, disable_act_quant=False
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): ReLU(inplace=True)
        )
        (conv2): QuantModule(
          wbit=4, abit=4, disable_act_quant=True
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): StraightThrough()
        )
        (activation_function): ReLU(inplace=True)
        (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
      )
    )
    (layer3): Sequential(
      (0): QuantBasicBlock(
        (conv1): QuantModule(
          wbit=4, abit=4, disable_act_quant=False
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): ReLU(inplace=True)
        )
        (conv2): QuantModule(
          wbit=4, abit=4, disable_act_quant=True
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): StraightThrough()
        )
        (downsample): QuantModule(
          wbit=4, abit=4, disable_act_quant=True
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): StraightThrough()
        )
        (activation_function): ReLU(inplace=True)
        (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
      )
      (1): QuantBasicBlock(
        (conv1): QuantModule(
          wbit=4, abit=4, disable_act_quant=False
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): ReLU(inplace=True)
        )
        (conv2): QuantModule(
          wbit=4, abit=4, disable_act_quant=True
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): StraightThrough()
        )
        (activation_function): ReLU(inplace=True)
        (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
      )
    )
    (layer4): Sequential(
      (0): QuantBasicBlock(
        (conv1): QuantModule(
          wbit=4, abit=4, disable_act_quant=False
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): ReLU(inplace=True)
        )
        (conv2): QuantModule(
          wbit=4, abit=4, disable_act_quant=True
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): StraightThrough()
        )
        (downsample): QuantModule(
          wbit=4, abit=4, disable_act_quant=True
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): StraightThrough()
        )
        (activation_function): ReLU(inplace=True)
        (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
      )
      (1): QuantBasicBlock(
        (conv1): QuantModule(
          wbit=4, abit=4, disable_act_quant=False
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): ReLU(inplace=True)
        )
        (conv2): QuantModule(
          wbit=4, abit=4, disable_act_quant=True
          (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
          (norm_function): StraightThrough()
          (activation_function): StraightThrough()
        )
        (activation_function): ReLU(inplace=True)
        (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): QuantModule(
      wbit=4, abit=4, disable_act_quant=True
      (weight_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
      (act_quantizer): UniformAffineQuantizer(bit=4, is_training=False, inited=True)
      (norm_function): StraightThrough()
      (activation_function): StraightThrough()
    )
  )
)
END : 2024-05-29 14:39:34
